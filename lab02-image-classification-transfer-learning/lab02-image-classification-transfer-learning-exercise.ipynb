{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430e7f7b",
   "metadata": {},
   "source": [
    "##### ARTI 560 - Computer Vision  \n",
    "## Image Classification using Transfer Learning - Exercise \n",
    "\n",
    "### Objective\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "1. Select another pretrained model (e.g., VGG16, MobileNetV2, or EfficientNet) and fine-tune it for CIFAR-10 classification.  \n",
    "You'll find the pretrained models in [Tensorflow Keras Applications Module](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "2. Before training, inspect the architecture using model.summary() and observe:\n",
    "- Network depth\n",
    "- Number of parameters\n",
    "- Trainable vs Frozen layers\n",
    "\n",
    "3. Then compare its performance with ResNet and the custom CNN.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- Which model achieved the highest accuracy?\n",
    "- Which model trained faster?\n",
    "- How might the architecture explain the differences?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e2f5f65",
   "metadata": {},
   "source": [
    "Student Name: Fajer Alzamanan\n",
    "Student ID: 2220006879\n",
    "Section No. : 10FA01\n",
    "\n",
    "### Exercise Description\n",
    "\n",
    "This notebook presents an implementation of transfer learning using **MobileNetV2** for CIFAR-10 image classification. The model architecture is analyzed in terms of network depth, number of parameters, and trainable versus frozen layers. The performance is then compared with **ResNet50V2** and a **Custom CNN** model to evaluate accuracy, computational efficiency, and architectural differences.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26d77e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ceec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cv_lab/lib/python3.13/site-packages/keras/src/datasets/cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "y_train = y_train.squeeze()\n",
    "y_test  = y_test.squeeze()\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test  = x_test.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ec2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "], name=\"augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaa06df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV2_TL\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV2_TL\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resizing (\u001b[38;5;33mResizing\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m12,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,270,794</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,270,794\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> (50.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,810\u001b[0m (50.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable weights: 2\n",
      "Non-trainable weights: 260\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # Freeze\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Resizing(224, 224, interpolation=\"bilinear\")(x)\n",
    "x = layers.Lambda(preprocess_input)(x)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(10)(x)  # logits (مثل lab02)\n",
    "\n",
    "mobile_model = keras.Model(inputs, outputs, name=\"MobileNetV2_TL\")\n",
    "\n",
    "mobile_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "mobile_model.summary()\n",
    "print(\"Trainable weights:\", len(mobile_model.trainable_weights))\n",
    "print(\"Non-trainable weights:\", len(mobile_model.non_trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e9a6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 513ms/step - accuracy: 0.6455 - loss: 1.0117 - val_accuracy: 0.8054 - val_loss: 0.5746\n",
      "Epoch 2/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 801ms/step - accuracy: 0.7220 - loss: 0.7967 - val_accuracy: 0.8238 - val_loss: 0.5042\n",
      "Epoch 3/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 512ms/step - accuracy: 0.7307 - loss: 0.7701 - val_accuracy: 0.8324 - val_loss: 0.4920\n",
      "MobileNetV2 (frozen) test acc: 0.8233\n",
      "Training time (s): 1287.3\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "history_m = mobile_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "m_loss, m_acc = mobile_model.evaluate(x_test, y_test, verbose=0)\n",
    "m_time = t1 - t0\n",
    "\n",
    "print(f\"MobileNetV2 (frozen) test acc: {m_acc:.4f}\")\n",
    "print(f\"Training time (s): {m_time:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a8447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 728ms/step - accuracy: 0.6945 - loss: 0.8966 - val_accuracy: 0.8256 - val_loss: 0.5073\n",
      "Epoch 2/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 718ms/step - accuracy: 0.7561 - loss: 0.6991 - val_accuracy: 0.8398 - val_loss: 0.4628\n",
      "Epoch 3/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 720ms/step - accuracy: 0.7814 - loss: 0.6306 - val_accuracy: 0.8498 - val_loss: 0.4182\n",
      "MobileNetV2 (fine-tuned) test acc: 0.8521\n",
      "Fine-tuning time (s): 1528.7\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "mobile_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "history_m_ft = mobile_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "mft_loss, mft_acc = mobile_model.evaluate(x_test, y_test, verbose=0)\n",
    "mft_time = t1 - t0\n",
    "\n",
    "print(f\"MobileNetV2 (fine-tuned) test acc: {mft_acc:.4f}\")\n",
    "print(f\"Fine-tuning time (s): {mft_time:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cc9667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 2270794\n",
      "Trainable params: 1539210\n",
      "Frozen params: 731584\n"
     ]
    }
   ],
   "source": [
    "def get_param_counts(model):\n",
    "    trainable = sum(np.prod(w.shape) for w in model.trainable_weights)\n",
    "    frozen = sum(np.prod(w.shape) for w in model.non_trainable_weights)\n",
    "    total = trainable + frozen\n",
    "    return total, trainable, frozen\n",
    "\n",
    "total_p, train_p, frozen_p = get_param_counts(mobile_model)\n",
    "print(\"Total params:\", total_p)\n",
    "print(\"Trainable params:\", train_p)\n",
    "print(\"Frozen params:\", frozen_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe879a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Frozen Accuracy</th>\n",
       "      <th>Fine-tuned Accuracy</th>\n",
       "      <th>Total Params</th>\n",
       "      <th>Trainable Params</th>\n",
       "      <th>Frozen Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Custom CNN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>Small (~1M)</td>\n",
       "      <td>All</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet50V2</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>23585290</td>\n",
       "      <td>20490</td>\n",
       "      <td>23564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>2270794</td>\n",
       "      <td>1539210</td>\n",
       "      <td>731584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Frozen Accuracy  Fine-tuned Accuracy Total Params  \\\n",
       "0   Custom CNN               -               0.8742  Small (~1M)   \n",
       "1   ResNet50V2          0.8742               0.9162     23585290   \n",
       "2  MobileNetV2          0.8233               0.8521      2270794   \n",
       "\n",
       "  Trainable Params  Frozen Params  \n",
       "0              All              0  \n",
       "1            20490       23564800  \n",
       "2          1539210         731584  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"Custom CNN\",\n",
    "        \"Frozen Accuracy\": \"-\",\n",
    "        \"Fine-tuned Accuracy\": 0.8742,\n",
    "        \"Total Params\": \"Small (~1M)\",\n",
    "        \"Trainable Params\": \"All\",\n",
    "        \"Frozen Params\": 0\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"ResNet50V2\",\n",
    "        \"Frozen Accuracy\": 0.8742,\n",
    "        \"Fine-tuned Accuracy\": 0.9162,\n",
    "        \"Total Params\": 23585290,\n",
    "        \"Trainable Params\": 20490,\n",
    "        \"Frozen Params\": 23564800\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"MobileNetV2\",\n",
    "        \"Frozen Accuracy\": 0.8233,\n",
    "        \"Fine-tuned Accuracy\": 0.8521,\n",
    "        \"Total Params\": 2270794,\n",
    "        \"Trainable Params\": 1539210,\n",
    "        \"Frozen Params\": 731584\n",
    "    }\n",
    "])\n",
    "\n",
    "comparison\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "238c1961",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "| Model       | Frozen Accuracy | Fine-tuned Accuracy | Total Parameters | Trainable Parameters | Frozen Parameters |\n",
    "| ----------- | --------------- | ------------------- | ---------------- | -------------------- | ----------------- |\n",
    "| Custom CNN  | —               | 0.8742              | Small (~1M)      | All                  | 0                 |\n",
    "| ResNet50V2  | 0.8742          | 0.9162              | 23,585,290       | 20,490               | 23,564,800        |\n",
    "| MobileNetV2 | 0.8233          | 0.8521              | 2,270,794        | 1,539,210            | 731,584           |\n",
    "\n",
    "---\n",
    "\n",
    "## Questions Answers\n",
    "\n",
    "### 1. Which model achieved the highest accuracy?\n",
    "\n",
    "Among the three models, **ResNet50V2** achieved the highest accuracy with approximately **91.6%** after fine-tuning. This superior performance is mainly due to its deep architecture and residual connections, which enable more effective feature extraction compared to the other models.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Which model trained faster?\n",
    "\n",
    "The **Custom CNN** trained the fastest because it has a simpler architecture and significantly fewer parameters compared to the pretrained models. **MobileNetV2** required moderate training time due to its lightweight design, while **ResNet50V2** took the longest training time because of its large number of parameters and deep network structure.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. How might the architecture explain the differences?\n",
    "\n",
    "The differences in performance can be explained by the architectural complexity of each model. The **Custom CNN** is relatively shallow with fewer parameters, which limits its ability to learn complex features but allows faster training. **ResNet50V2** is a very deep network with residual connections that improve gradient flow and feature learning, resulting in higher accuracy but increased computational cost. **MobileNetV2** uses depthwise separable convolutions, which significantly reduce the number of parameters and computations while maintaining good feature extraction capability, providing a balance between accuracy and efficiency. These results also demonstrate the advantage of transfer learning compared to training a model from scratch.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bee7528f",
   "metadata": {},
   "source": [
    "## Additional Observations\n",
    "\n",
    "The parameter statistics were obtained from the `model.summary()` outputs. ResNet50V2 has significantly more parameters than MobileNetV2 and the custom CNN, which increases computational cost but improves feature learning. MobileNetV2 reduces complexity using depthwise separable convolutions, providing efficient performance with fewer parameters. Fine-tuning improved the accuracy of the pretrained models compared to the frozen configuration, highlighting the benefit of transfer learning. Overall, the results demonstrate the trade-off between model complexity, efficiency, and accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d3478d524039e6c112eb059b2826a06fb71b4fb675d05fbecb3b8139d7d49b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
